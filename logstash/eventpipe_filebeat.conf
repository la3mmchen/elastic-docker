input {
  kafka {
    bootstrap_servers => "kafka-1:9092"
    topics => ['filebeat-log']
    add_field => {
      "pipe" => "via_kafka"
      }
    enable_auto_commit => true
    auto_offset_reset => "latest" # we don't want to parse the queue again
    decorate_events => true
    group_id => "logstash-applog"
    auto_commit_interval_ms => "5000"
    codec => "json"
  }
}
filter {
  if [pipe] == "via_kafka" {
    json {
       source => "[message]"
       target => "event"
    }
    mutate {
       rename => { "[event][message]" => "[event][event_message]" }
       replace => { "type" => "kafka_applog" }
     }
  }
}
output {
  if [pipe] == "via_kafka" {
    elasticsearch {
      hosts => [ 'http://elastic-1:9200' ]
      index => "%{type}-%{+YYYY.MM.dd}"
      document_type => "%{[@metadata][type]}"
      user => "elastic"
      password => "changeme"
    }
  }
  elasticsearch {
    hosts => [ 'http://elastic-1:9200' ]
    index => "all-metrics-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "changeme"
  }
}
